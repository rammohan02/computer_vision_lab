{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR ANOTHER PRODUCT COMMENT THE PRODUCT IMAGES GIVEN\n",
    "#OUTPUT WILL BE SHOWN IN THE CURRENT DIRECTORY FOR THE IMAGES GIVEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#To remove salt and pepper noise. using median filter to remove noice\n",
    "def filterOutSaltPepperNoise(edgeImg):\n",
    "    ctr = 0\n",
    "    lastMedian = edgeImg\n",
    "    median = cv2.medianBlur(edgeImg, 3)\n",
    "    while not np.array_equal(lastMedian, median):\n",
    "        # get those pixels that gets zeroed out\n",
    "        zeroed = np.invert(np.logical_and(median, edgeImg))\n",
    "        edgeImg[zeroed] = 0\n",
    "\n",
    "        ctr = ctr + 1\n",
    "        if ctr > 50:\n",
    "            break\n",
    "        lastMedian = median\n",
    "        median = cv2.medianBlur(edgeImg, 3)\n",
    "\n",
    "#to find edge contours\n",
    "def findLargestContour(edgeImg):\n",
    "    contours, hierarchy = cv2.findContours(edgeImg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #retr_external takes only extreme countors\n",
    "    #chain_approx_simple returns the points that are only necessary for drawing contours\n",
    "    \n",
    "    #eliminating contours with smaller ares\n",
    "    contoursWithArea = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        contoursWithArea.append([contour, area])\n",
    "\n",
    "    contoursWithArea.sort(key=lambda tupl: tupl[1], reverse=True)\n",
    "    largestContour = contoursWithArea[0][0]\n",
    "    return largestContour\n",
    "\n",
    "\n",
    "def back_ground_removal(img):\n",
    "    \n",
    "    #src = cv2.imread('b_org1.jpeg')\n",
    "    src = img\n",
    "    blurred = cv2.GaussianBlur(src, (5, 5), 0)\n",
    "\n",
    "    blurred_float = blurred.astype(np.float32) / 255.0\n",
    "    #This model does edge detection better with keeping much noises\n",
    "    edgeDetector = cv2.ximgproc.createStructuredEdgeDetection(\"model.yml\")\n",
    "    #this fn returns 1 for edge, below we are doing *255 to get edge\n",
    "    edges = edgeDetector.detectEdges(blurred_float) * 220.0\n",
    "    \n",
    "    #cv2.imwrite('edge-raw.jpg', edges)\n",
    "\n",
    "    #converting the input into datatype of uint8\n",
    "    edges_8u = np.asarray(edges, np.uint8)\n",
    "    filterOutSaltPepperNoise(edges_8u)\n",
    "    cv2.imwrite('edge.jpg', edges_8u)\n",
    "\n",
    "    #after removing noise find edge countor\n",
    "    contour = findLargestContour(edges_8u)\n",
    "    # Draw the contour on the original image\n",
    "    contourImg = np.copy(src)\n",
    "    cv2.drawContours(contourImg, [contour], 0, (255, 0, 0), 2, cv2.LINE_AA, maxLevel=1)\n",
    "    cv2.imwrite('contour.jpg', contourImg)\n",
    "\n",
    "    #creating mask along edges\n",
    "    mask = np.zeros_like(edges_8u)\n",
    "    cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "    #dialating to calculate foreground\n",
    "    mapFg = cv2.erode(mask, np.ones((5, 5), np.uint8), iterations=10)\n",
    "\n",
    "    #estimating the foreground and background for grabcut\n",
    "    trimap = np.copy(mask)\n",
    "    trimap[mask == 0] = cv2.GC_BGD\n",
    "    trimap[mask == 255] = cv2.GC_PR_BGD\n",
    "    trimap[mapFg == 255] = cv2.GC_FGD\n",
    "\n",
    "    #grabcut\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (0, 0, mask.shape[0] - 1, mask.shape[1] - 1)\n",
    "    #bgmodel-temporary bg\n",
    "    cv2.grabCut(src, trimap, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "    # create mask again\n",
    "    mask2 = np.where((trimap == cv2.GC_FGD) | (trimap == cv2.GC_PR_FGD), 255, 0).astype('uint8')\n",
    "    \n",
    "    #cv2.imwrite('mask2.jpg', mask2)\n",
    "\n",
    "    #doing contour detection to avoid if holes/still background is present appear inside image\n",
    "    contour2 = findLargestContour(mask2)\n",
    "    mask3 = np.zeros_like(mask2)\n",
    "    cv2.fillPoly(mask3, [contour2], 255)\n",
    "\n",
    "\n",
    "    #to increase the intensity for smoothing the edges\n",
    "    mask3 = np.repeat(mask3[:, :, np.newaxis], 3, axis=2)\n",
    "    mask4 = cv2.GaussianBlur(mask3, (3, 3), 0)\n",
    "    alpha = mask4.astype(float) * 1.1  # making blend stronger\n",
    "    alpha[mask3 > 0] = 255.0\n",
    "    alpha[alpha > 255] = 255.0\n",
    "\n",
    "    #assigning the color values to foreground\n",
    "    foreground = np.copy(src).astype(float)\n",
    "    foreground[mask4 == 0] = 0\n",
    "    background = np.ones_like(foreground, dtype=float) * 255.0\n",
    "\n",
    "    #cv2.imwrite('foreground.png', foreground)\n",
    "    #cv2.imwrite('background.png', background)\n",
    "    #cv2.imwrite('alpha.png', alpha)\n",
    "\n",
    "    # Normalize the alpha mask to keep intensity between 0 and 1. so we can multiply with foreround and foreground to make\n",
    "    #it final.\n",
    "    alpha = alpha / 255.0\n",
    "    # Multiply the foreground with the alpha matte\n",
    "    foreground = cv2.multiply(alpha, foreground)\n",
    "    # Multiply the background with ( 1 - alpha )\n",
    "    background = cv2.multiply(1.0 - alpha, background)\n",
    "    # Add the masked foreground and background.\n",
    "    cutout = cv2.add(foreground, background)\n",
    "\n",
    "    #FINAL IMAGE AFTER REMOVING BACKGROUND\n",
    "    #cv2.imwrite('cutout.jpg', cutout)\n",
    "    return cutout\n",
    "\n",
    "\n",
    "\n",
    "# Original Reference\n",
    "# ref = cv2.imread(\"paste/paste_org.jpg\")\n",
    "ref = cv2.imread(\"bottle/b2.jpg\")\n",
    "print(\"B\")\n",
    "\n",
    "# Calling function\n",
    "image_ref = back_ground_removal(ref)\n",
    "\n",
    "# Saving reference after emoving background\n",
    "cv2.imwrite(\"Org.jpg\", image_ref)\n",
    "# print(image_ref)\n",
    "\n",
    "\n",
    "# Duplicate / image given by user\n",
    "# src = cv2.imread(\"paste/paste_dup.jpg\")\n",
    "src = cv2.imread(\"bottle/bi3_dup.jpeg\")\n",
    "print(\"A\")\n",
    "\n",
    "# Calling function\n",
    "image = back_ground_removal(src)\n",
    "\n",
    "# Saving Image After removing background\n",
    "cv2.imwrite(\"Dup.jpg\", image)\n",
    "# print(image)\n",
    "\n",
    "\n",
    "cv2.imshow(\"org\", image_ref)\n",
    "cv2.imshow(\"dup\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How good 2nd image is  8.557457212713937\n",
      "There is very low similarity with original image. We consider it as duplicate\n"
     ]
    }
   ],
   "source": [
    "def image_cmp(image1, image1_ref):\n",
    "    img_ref = image1_ref\n",
    "    img = image1\n",
    "\n",
    "    img_ref = cv2.resize(img_ref, (960, 540))\n",
    "    img = cv2.resize(img, (960, 540))\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    kp_1, desc_1 = sift.detectAndCompute(img_ref, None)\n",
    "    kp_2, desc_2 = sift.detectAndCompute(img, None)\n",
    "\n",
    "    # print(\"Key points 1st image \" + str(len(kp_1)))\n",
    "    # print(\"Key points 2nd image \" + str(len(kp_2)))\n",
    "    \n",
    "\n",
    "    ''' Brute force method\n",
    "    bf = cv2.BFMatcher(\n",
    "        # cv2.NORM_L2, \n",
    "        # crossCheck=True\n",
    "        )\n",
    "\n",
    "    Match descriptors.\n",
    "    matches = bf.match(des1,des2)\n",
    "    matches=bf.knnMatch(desc_1, desc_2, k=2)\n",
    "    '''\n",
    "\n",
    "    # FLANN BASED MATCHING\n",
    "\n",
    "    index_params = dict(algorithm=0, trees=5)\n",
    "    search_params = dict()\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch(desc_1, desc_2, k=2)\n",
    "\n",
    "    # flann identifies nearest neighbours, knn srearch for k closet key points\n",
    "    # It gives list with set of two points in it which contains feature vector of image1 and image2\n",
    "\n",
    "    good_points = []\n",
    "\n",
    "    for m, n in matches:\n",
    "        if(m.distance < 0.85*n.distance):\n",
    "            good_points.append(m)\n",
    "\n",
    "\n",
    "    # print(len(matches))\n",
    "    # print(\"Good matches \" + str(len(good_points)))\n",
    "\n",
    "    points = min(len(kp_1), len(kp_2))\n",
    "    perc = len(good_points)/points * 100\n",
    "    print(\"How good 2nd image is \", perc)\n",
    "\n",
    "    result = cv2.drawMatches(img_ref, kp_1, img, kp_2, good_points, None)\n",
    "\n",
    "    result = cv2.resize(result, (960, 540))\n",
    "\n",
    "    cv2.imshow(\"result\", result)\n",
    "    cv2.imwrite(\"result.png\", result)\n",
    "    cv2.imshow(\"Ref\", img_ref)\n",
    "    cv2.imshow(\"Img\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return perc\n",
    "\n",
    "    \n",
    "image = cv2.imread(\"Dup.jpg\")\n",
    "# image = cv2.resize(image, (960, 540))\n",
    "image_ref = cv2.imread(\"Org.jpg\")\n",
    "# image_ref = cv2.resize(image_ref, (960, 540))\n",
    "\n",
    "cmp_perc = image_cmp(image, image_ref)\n",
    "\n",
    "if(cmp_perc>20):\n",
    "    print(\"We have a similarity with the original image. We consider it as Original\")\n",
    "else:\n",
    "    print(\"There is very low similarity with original image. We consider it as duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
